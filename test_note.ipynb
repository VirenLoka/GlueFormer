{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "50d93155-88ec-406d-a62e-4cf82942dd70",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 0 is out of bounds for dimension 0 with size 0",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mIndexError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 17\u001b[39m\n\u001b[32m      9\u001b[39m tok_cfg = cfg[\u001b[33m\"\u001b[39m\u001b[33mtokenizer\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m     10\u001b[39m tokenizer = SmilesTokenizer(\n\u001b[32m     11\u001b[39m     pad_token=tok_cfg[\u001b[33m\"\u001b[39m\u001b[33mpad_token\u001b[39m\u001b[33m\"\u001b[39m],\n\u001b[32m     12\u001b[39m     bos_token=tok_cfg[\u001b[33m\"\u001b[39m\u001b[33mbos_token\u001b[39m\u001b[33m\"\u001b[39m],\n\u001b[32m   (...)\u001b[39m\u001b[32m     15\u001b[39m     max_len=tok_cfg[\u001b[33m\"\u001b[39m\u001b[33mmax_len\u001b[39m\u001b[33m\"\u001b[39m],\n\u001b[32m     16\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m17\u001b[39m model = \u001b[43mSmilesTransformer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfrom_config\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcfg\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmodel\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[43m)\u001b[49m.to(device)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/GlueFormer/model.py:243\u001b[39m, in \u001b[36mSmilesTransformer.from_config\u001b[39m\u001b[34m(cls, model_cfg, tokenizer)\u001b[39m\n\u001b[32m    240\u001b[39m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[32m    241\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mfrom_config\u001b[39m(\u001b[38;5;28mcls\u001b[39m, model_cfg: \u001b[38;5;28mdict\u001b[39m, tokenizer) -> \u001b[33m\"\u001b[39m\u001b[33mSmilesTransformer\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    242\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Instantiate from a config dict + tokenizer.\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m243\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[32m    244\u001b[39m \u001b[43m        \u001b[49m\u001b[43mvocab_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvocab_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    245\u001b[39m \u001b[43m        \u001b[49m\u001b[43md_model\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel_cfg\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43md_model\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    246\u001b[39m \u001b[43m        \u001b[49m\u001b[43mn_heads\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel_cfg\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mn_heads\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    247\u001b[39m \u001b[43m        \u001b[49m\u001b[43mn_layers\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel_cfg\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mn_layers\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    248\u001b[39m \u001b[43m        \u001b[49m\u001b[43md_ff\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel_cfg\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43md_ff\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    249\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdropout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel_cfg\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mdropout\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    250\u001b[39m \u001b[43m        \u001b[49m\u001b[43mactivation\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel_cfg\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mactivation\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mgelu\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    251\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmax_len\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmax_len\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    252\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpad_idx\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    253\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/GlueFormer/model.py:117\u001b[39m, in \u001b[36mSmilesTransformer.__init__\u001b[39m\u001b[34m(self, vocab_size, d_model, n_heads, n_layers, d_ff, dropout, activation, max_len, pad_idx)\u001b[39m\n\u001b[32m    114\u001b[39m \u001b[38;5;28mself\u001b[39m.max_len = max_len\n\u001b[32m    115\u001b[39m \u001b[38;5;28mself\u001b[39m.d_model = d_model\n\u001b[32m--> \u001b[39m\u001b[32m117\u001b[39m \u001b[38;5;28mself\u001b[39m.tok_emb = \u001b[43mnn\u001b[49m\u001b[43m.\u001b[49m\u001b[43mEmbedding\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvocab_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43md_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadding_idx\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpad_idx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    118\u001b[39m \u001b[38;5;28mself\u001b[39m.pos_emb = nn.Embedding(max_len, d_model)\n\u001b[32m    119\u001b[39m \u001b[38;5;28mself\u001b[39m.drop = nn.Dropout(dropout)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/lib/python3.13/site-packages/torch/nn/modules/sparse.py:171\u001b[39m, in \u001b[36mEmbedding.__init__\u001b[39m\u001b[34m(self, num_embeddings, embedding_dim, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse, _weight, _freeze, device, dtype)\u001b[39m\n\u001b[32m    166\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m _weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    167\u001b[39m     \u001b[38;5;28mself\u001b[39m.weight = Parameter(\n\u001b[32m    168\u001b[39m         torch.empty((num_embeddings, embedding_dim), **factory_kwargs),\n\u001b[32m    169\u001b[39m         requires_grad=\u001b[38;5;129;01mnot\u001b[39;00m _freeze,\n\u001b[32m    170\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m171\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mreset_parameters\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    172\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    173\u001b[39m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(_weight.shape) == [\n\u001b[32m    174\u001b[39m         num_embeddings,\n\u001b[32m    175\u001b[39m         embedding_dim,\n\u001b[32m    176\u001b[39m     ], \u001b[33m\"\u001b[39m\u001b[33mShape of weight does not match num_embeddings and embedding_dim\u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/lib/python3.13/site-packages/torch/nn/modules/sparse.py:183\u001b[39m, in \u001b[36mEmbedding.reset_parameters\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    181\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mreset_parameters\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    182\u001b[39m     init.normal_(\u001b[38;5;28mself\u001b[39m.weight)\n\u001b[32m--> \u001b[39m\u001b[32m183\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_fill_padding_idx_with_zero\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/lib/python3.13/site-packages/torch/nn/modules/sparse.py:188\u001b[39m, in \u001b[36mEmbedding._fill_padding_idx_with_zero\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    186\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.padding_idx \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    187\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m torch.no_grad():\n\u001b[32m--> \u001b[39m\u001b[32m188\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpadding_idx\u001b[49m\u001b[43m]\u001b[49m.fill_(\u001b[32m0\u001b[39m)\n",
      "\u001b[31mIndexError\u001b[39m: index 0 is out of bounds for dimension 0 with size 0"
     ]
    }
   ],
   "source": [
    "from model import *\n",
    "import yaml\n",
    "from tokenizer import *\n",
    "from dataset import *\n",
    "def load_config(path: str) -> dict:\n",
    "    with open(path) as f:\n",
    "        return yaml.safe_load(f)\n",
    "\n",
    "cfg = load_config('configs/train_config.yaml')\n",
    "tok_cfg = cfg[\"tokenizer\"]\n",
    "tokenizer = SmilesTokenizer(\n",
    "    pad_token=tok_cfg[\"pad_token\"],\n",
    "    bos_token=tok_cfg[\"bos_token\"],\n",
    "    eos_token=tok_cfg[\"eos_token\"],\n",
    "    unk_token=tok_cfg[\"unk_token\"],\n",
    "    max_len=tok_cfg[\"max_len\"],\n",
    ")\n",
    "tokenizer.build_vocab\n",
    "model = SmilesTransformer.from_config(cfg[\"model\"], tokenizer).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efda6e53-6d67-4f41-9282-6a10f591a84f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6f293bd-e743-40f4-bd93-f74d7e6cdcf6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "glue_env",
   "language": "python",
   "name": "glueformer"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
